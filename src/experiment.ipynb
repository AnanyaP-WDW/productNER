{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0938846d3a607f3f244609a92d954017c578d0118fd62ed0861ca010603b27814",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "938846d3a607f3f244609a92d954017c578d0118fd62ed0861ca010603b27814"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "import re\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "# doc = nlp(\"cantata (smash)hazelnut incense coffee beans 600g mocha blend\")\n",
    "# doc1 = nlp(\"[sales cafe] hazelnut incense coffee beans( 200g 500g 1kg )\")\n",
    "# doc3 = nlp(\"sanjibyeolsaengdu santos, brazil NY2 1Bag 60kg\")\n",
    "# doc4 = nlp(\"espresso bold dark 1kg SRBC140FC0500A02 coffee beans\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"ca76af119139480aae3a4efc56355b59-0\" class=\"displacy\" width=\"1275\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">sanjibyeolsaengdu</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">ADV</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">santos,</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">brazil</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">NOUN</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">NY2</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">PROPN</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">1Bag</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NUM</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">60</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">NUM</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">kg</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">NOUN</tspan>\n</text>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-ca76af119139480aae3a4efc56355b59-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-ca76af119139480aae3a4efc56355b59-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-ca76af119139480aae3a4efc56355b59-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-ca76af119139480aae3a4efc56355b59-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M395.0,179.0 L403.0,167.0 387.0,167.0\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-ca76af119139480aae3a4efc56355b59-0-2\" stroke-width=\"2px\" d=\"M245,177.0 C245,2.0 575.0,2.0 575.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-ca76af119139480aae3a4efc56355b59-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">appos</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M575.0,179.0 L583.0,167.0 567.0,167.0\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-ca76af119139480aae3a4efc56355b59-0-3\" stroke-width=\"2px\" d=\"M770,177.0 C770,2.0 1100.0,2.0 1100.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-ca76af119139480aae3a4efc56355b59-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nummod</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M770,179.0 L762,167.0 778,167.0\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-ca76af119139480aae3a4efc56355b59-0-4\" stroke-width=\"2px\" d=\"M945,177.0 C945,89.5 1095.0,89.5 1095.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-ca76af119139480aae3a4efc56355b59-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nummod</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M945,179.0 L937,167.0 953,167.0\" fill=\"currentColor\"/>\n</g>\n</svg></span>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "displacy.render(doc3)\n",
    "# doc3[7].dep_, doc3[7], doc3[7].pos_\n",
    "# doc3[6].dep_, doc3[6], doc3[6].pos_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cardinal number\nsanjibyeolsaengdu sanjibyeolsaengdu\nsantos santo\n, ,\nbrazil brazil\nNY2 NY2\n1Bag 1bag\n60 60\nkg kg\n"
     ]
    }
   ],
   "source": [
    "# print(spacy.explain(\"npadvmod\"))\n",
    "# print(spacy.explain(\"nummod\"))\n",
    "# print(spacy.explain(\"DET\"))\n",
    "# print(spacy.explain(\"quantmod\"))\n",
    "print(spacy.explain(\"CD\"))\n",
    "# noun phrase as adverbial modifier\n",
    "# numeric modifier\n",
    "# determiner\n",
    "# Looking at dependencies to make logic\n",
    "for t in doc3:\n",
    "    print(t,t.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "600g\n200G\n567g\n13oz(369g\n200g\n1kg\nblend(500g\n500g\n340g\n865g\n720g\n100g\nbeans(200g\nNone\nNone\n227g\n1kg\n1Bag(60kg\n"
     ]
    }
   ],
   "source": [
    "def detect_weight(input_string):\n",
    "    # input is doc type from spacy\n",
    "    wanted_pos = ['NOUN', 'PROPN']\n",
    "    for idx,t in enumerate(input_string):\n",
    "        if t.lower_ in [\"g\", \" g \", \"kg\", \" kg \", \"oz\", \" oz \"]:\n",
    "                # if t.pos_ == 'PROPN':\n",
    "                #     return str(t)\n",
    "                # elif t.pos_ == 'NOUN' and input_string[idx -1].pos_ == 'NUM':\n",
    "                #     return str(input_string[idx -1]) + str(t)\n",
    "                return str(input_string[idx-1]) + str(t)\n",
    "    return \"None\"\n",
    "for item in z:\n",
    "    print(detect_weight(nlp(item)))\n",
    "#     \"\"\"cantata (smash)hazelnut incense coffee beans 600g/mocha blend\n",
    "# Costa costa signature blend coffee bean 200G x 2\n",
    "# starbucks veranda blend light smash coffee 567g 2 pack\n",
    "# trader joe organic french roast 13oz(369g) x2 pack\n",
    "# [blackvins]mandeling, indonesia coffee beans after ordering roasting 200g\n",
    "# for restaurant prima vending machine cohabitation 1kg coffee prim business\n",
    "# [117557]ethiopia special blend(500g/fine grinding/mr bin)\n",
    "# [keopimandeulgi] kenya aa TOP 500g\n",
    "# rabbah intensos dark roast coffee beans powder 340g 3 piece\n",
    "# pauls ground coffee beans 865g coffee powder drip coffee\n",
    "# pauls breakfast blend mild light roast ground coffee 720g\n",
    "# indonesia sumatra mandeling 100g coffee beans roasting on the day\n",
    "# [sales cafe] hazelnut incense coffee beans(200g/500g/1kg)\n",
    "# espresso bold dark 1kg(SRBC140FC0500A02)coffee beans\n",
    "# el salvador fancy 1kg(SROC120CI0500A02) gobgebunswae/gajeongyongeseupeureso/mocha pot(M)\n",
    "# [coffee pilgrims] guatemala shb beans coffee/227g 1 rod(8oz 1 rod) /single origin\n",
    "# brazil serado coffee beans 1kg roasting on the day\n",
    "# sanjibyeolsaengdu santos, brazil NY2 1Bag(60kg)\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [('cantata smash hazelnut incense coffee beans 600g mocha blend', {'entities': [(44, 48, 'MEASURE')]}), ('Costa costa signature blend coffee bean 200G x 2', {'entities': [(40, 44, 'MEASURE')]}), ('starbucks veranda blend light smash coffee 567g 2 pack', {'entities': [(43, 47, 'MEASURE')]}), ('trader joe organic french roast 13oz 369g x2 pack', {'entities': [(32, 36, 'MEASURE'), (37, 41, 'MEASURE')]}), ('[blackvins]mandeling, indonesia coffee beans after ordering roasting 200g', {'entities': [(69, 73, 'MEASURE')]}), ('for restaurant prima vending machine cohabitation 1kg coffee prim business', {'entities': [(50, 53, 'MEASURE')]}), ('[117557]ethiopia special blend 500g fine grinding mr bin', {'entities': [(31, 35, 'MEASURE')]}), ('[keopimandeulgi] kenya aa TOP 500g', {'entities': [(30, 34, 'MEASURE')]}), ('rabbah intensos dark roast coffee beans powder 340g 3 piece', {'entities': [(47, 51, 'MEASURE')]}), ('pauls ground coffee beans 865g coffee powder drip coffee', {'entities': [(26, 30, 'MEASURE')]}), ('pauls breakfast blend mild light roast ground coffee 720g', {'entities': [(53, 57, 'MEASURE')]}), ('indonesia sumatra mandeling 100g coffee bea 200g 500g 1kg', {'entities': [(28, 32, 'MEASURE'), (44, 48, 'MEASURE'), (49, 53, 'MEASURE'), (54, 57, 'MEASURE')]}), ('espresso bold dark 1kg SRBC140FC0500A02 ns roasting on the day', {'entities': [(19, 22, 'MEASURE')]}), ('el salvador fancy 1kg SROC120CI0500A02 gobgebunswae gajeongyongeseupeureso mocha pot M', {'entities': [(18, 21, 'MEASURE')]}), ('[coffee pilgrims] guatemala shb beans coffee 227g 1 rod 8oz 1 rod single origin', {'entities': [(45, 49, 'MEASURE'), (56, 59, 'MEASURE')]}), ('brazil serado coffee beans 1kg roasting on the day', {'entities': [(27, 30, 'MEASURE')]}), ('sanjibyeolsaengdu santos, brazil NY2 1Bag 60kg', {'entities': [(42, 46, 'MEASURE')]})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'span'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-7f186eb0b7d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0minput_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mclean_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minput_text\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_string\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mparse_train_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-7f186eb0b7d9>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0minput_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mclean_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minput_text\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_string\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mparse_train_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-7f186eb0b7d9>\u001b[0m in \u001b[0;36mparse_train_data\u001b[0;34m(doc)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mstart_idx_overall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_idx_overall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_char\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_char\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mre_match\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'(\\d+)'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_idx_overall\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend_idx_overall\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mstart_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre_match\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mvalue_of_measure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_num\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_char\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_num\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_char\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'value_of_measure'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0munit_of_measure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mend_num\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend_idx_overall\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_char\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mend_num\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend_idx_overall\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_char\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'unit_of_measure'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'span'"
     ]
    }
   ],
   "source": [
    "from spacy.matcher import Matcher\n",
    "import re\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def parse_train_data(doc):\n",
    "    start_for_product_name = matcher(doc)[0][1]\n",
    "    #unit_list = ['grams','g','kg','kilograms','mg','oz','lb','lbs','ml','l','liter','liters']\n",
    "    # measure_detections = [(doc[start:end].start_char, doc[start:end].end_char, 'MEASURE') for idx, start, end in matcher(doc)]\n",
    "    \n",
    "    for idx, start, end in matcher(doc):\n",
    "        start_idx_overall, end_idx_overall = doc[start:end].start_char, doc[start:end].end_char\n",
    "        re_match = re.match('(\\d+)',str(doc[start_idx_overall:end_idx_overall]))\n",
    "        start_num, end_num = re_match.span()\n",
    "        value_of_measure = (doc[start_num:end_num].start_char, doc[start_num:end_num].end_char, 'value_of_measure')\n",
    "        unit_of_measure = (doc[end_num+1:end_idx_overall].start_char, doc[end_num+1:end_idx_overall].end_char, 'unit_of_measure')\n",
    "        measure_detections = value_of_measure.extend(unit_of_measure)\n",
    "    return (doc.text, {'entities': measure_detections})\n",
    "\n",
    "def clean_text(input_text):\n",
    "    input_text =  input_text.strip()\n",
    "    # \n",
    "    input_text = re.sub(r\"[\\n\\t<>()/]\", \" \", input_text)\n",
    "    input_text = \" \".join(input_text.split())\n",
    "    \n",
    "    return input_text\n",
    "\n",
    "overall_pattern = [{'LIKE_NUM': True},\n",
    "        {'LOWER':{'IN':['grams','g','kg','kilograms','mg','oz','lb','lbs','ml','l','liter','liters' ]}}\n",
    "        ]\n",
    "#unit_pattern = [{'LOWER': {'IN':['grams','g','kg','kilograms','mg','oz','lb','lbs','ml','l','liter','liters' ]}}]\n",
    "\n",
    "\n",
    "input_string = \"\"\"beans 600g/mocha blend\n",
    "    200G x 2\n",
    "    567g 2 pack\n",
    "    trader joe organic french roast 13oz(369g) x2 pack\n",
    "    [blackvins]mandeling, indonesia coffee beans after ordering roasting 200g\"\"\"\n",
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "matcher.add(\"Measure\", [overall_pattern])\n",
    "#matcher.add(\"Measure\", [unit_pattern])\n",
    "\n",
    "input_text = [clean_text(input_text) for input_text in input_string.splitlines()] \n",
    "train_data = [parse_train_data(d) for d in nlp.pipe(input_text) if len(matcher(d)) >= 1]\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"beans 600g mocha blend\")\n",
    "for idx, start, end in matcher(doc):\n",
    "    matcher = Matcher(nlp.vocab)\n",
    "    overall_pattern = [{'LIKE_NUM': True},\n",
    "        {'LOWER':{'IN':['grams','g','kg','kilograms','mg','oz','lb','lbs','ml','l','liter','liters' ]}}\n",
    "        ]\n",
    "    matcher.add(\"Measure\", [overall_pattern])\n",
    "    start_idx_overall, end_idx_overall = doc[start:end].start_char, doc[start:end].end_char\n",
    "    re_match = re.match('(\\d+)',str(doc[start_idx_overall:end_idx_overall]))\n",
    "    print(str(doc[start_idx_overall:end_idx_overall]))\n",
    "    #start_num, end_num = re_match.span()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}